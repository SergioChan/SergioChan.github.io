<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    
    <title>我是怎么踩过在 OSX 上录屏的坑的 | Sergio Chan</title>
    <meta name="renderer" content="webkit">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <meta name="description" content="Crazy fan of Hackathons all around the world. &lt;br/&gt; Currently works for &lt;em&gt;&lt;strong&gt;RavenLab Team&lt;/strong&gt;&lt;/em&gt; &lt;a href=&quot;http://www.raventech.com&quot; style=&quot;text-decoration:underline;&quot;&gt;@RavenTech.Inc&lt;/a&gt;">

    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="我是怎么踩过在 OSX 上录屏的坑的 | Sergio Chan">
    <meta name="twitter:description" content="Crazy fan of Hackathons all around the world. &lt;br/&gt; Currently works for &lt;em&gt;&lt;strong&gt;RavenLab Team&lt;/strong&gt;&lt;/em&gt; &lt;a href=&quot;http://www.raventech.com&quot; style=&quot;text-decoration:underline;&quot;&gt;@RavenTech.Inc&lt;/a&gt;">

    <meta property="og:type" content="article">
    <meta property="og:title" content="我是怎么踩过在 OSX 上录屏的坑的 | Sergio Chan">
    <meta property="og:description" content="Crazy fan of Hackathons all around the world. &lt;br/&gt; Currently works for &lt;em&gt;&lt;strong&gt;RavenLab Team&lt;/strong&gt;&lt;/em&gt; &lt;a href=&quot;http://www.raventech.com&quot; style=&quot;text-decoration:underline;&quot;&gt;@RavenTech.Inc&lt;/a&gt;">

    
    <meta name="author" content="Sergio Chan">
    
    <link rel="stylesheet" href="/css/vno.css" type="text/css">
    <link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" type="text/css">

    
    <link rel="icon" href="/favicon.ico">
    

    <meta name="generator" content="hexo"/>
    

    <link rel="canonical" href="http://sergiochan.github.io/2016/03/23/我是怎么踩过在-OSX-上录屏的坑的/"/>

    
    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?030a47db2df6601bda0225610cd6c323";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

</head>

<body class="home-template no-js">

    <span class="mobile btn-mobile-menu">
        <i class="fa fa-list btn-mobile-menu__icon"></i>
        <i class="fa fa-angle-up btn-mobile-close__icon hidden"></i>
    </span>

    
<header class="panel-cover panel-cover--collapsed" style="">
  <div class="panel-main">
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        <a href="/" title="前往 Sergio Chan 的主页"><img src="https://avatars2.githubusercontent.com/u/10103766?v=3&amp;s=460" width="80" alt="Sergio Chan logo" class="panel-cover__logo logo" /></a>
        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage for Sergio Chan">Sergio Chan</a></h1>
        
        <span class="panel-cover__subtitle panel-subtitle">Born hacker, Full-stack Developer</span>
        
        <hr class="panel-cover__divider" />
        <p class="panel-cover__description">Crazy fan of Hackathons all around the world. <br/> Currently works for <em><strong>RavenLab Team</strong></em> <a href="http://www.raventech.com" style="text-decoration:underline;">@RavenTech.Inc</a>.</p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />

        <div class="navigation-wrapper">
          <div>
          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">
              <li class="navigation__item"><a href="/archives" title="" class="blog-button">Blog</a></li>
            
              <li class="navigation__item"><a href="/bio">Biography</a></li>
            
              <li class="navigation__item"><a href="/about">About</a></li>
            
              <li class="navigation__item"><a href="/portfolio">Portfolio</a></li>
            
            </ul>
          </nav>
          </div>
          <div>
          <nav class="cover-navigation navigation--social">
  <ul class="navigation">

  <!-- Weibo-->
  
  <li class="navigation__item">
    <a href="http://weibo.com/3089081773/profile?topnav=1&amp;wvr=6" title="My Weibo" target="_blank">
      <i class='social fa fa-weibo'></i>
      <span class="label">Weibo</span>
    </a>
  </li> 


  <!-- Github -->
  
  <li class="navigation__item">
    <a href="https://github.com/SergioChan" title="My Github" target="_blank">
      <i class='social fa fa-github'></i>
      <span class="label">Github</span>
    </a>
  </li>


<!-- Stack Overflow -->
        

  <!-- Google Plus -->
  

<!-- Facebook -->

  
<!-- Twitter -->

  <li class="navigation__item">
    <a href="https://twitter.com/Sergio2Chan" title="Twitter" target="_blank">
      <i class='social fa fa-twitter'></i>
      <span class="label">Twitter</span>
    </a>
  </li>


<li class="navigation__item">
  <a href="https://dribbble.com/SergioChan" title="Dribbble" target="_blank">
    <i class='social fa fa-dribbble'></i>
    <span class="label">Dribbble</span>
  </a>
</li>

<!-- Linkedin -->

  <li class="navigation__item">
    <a href="http://www.linkedin.com/in/sergiochan" title="Linkedin" target="_blank">
      <i class='social fa fa-linkedin'></i>
      <span class="label">Linkedin</span>
    </a>
  </li>




  <li class="navigation__item">
    <a href="mailto:cyh9211@icloud.com" title="Email" target="_blank">
      <i class='social fa fa-envelope'></i>
      <span class="label">Email</span>
    </a>
  </li>


  </ul>
</nav>

          </div>
        </div>

      </div>

    </div>

    <div class="panel-cover--overlay cover-slate"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner">
            <article class="post-container post-container--single">

  <header class="post-header">
    <div class="post-meta">
      <time datetime="2016-03-23T15:55:44.000Z" class="post-list__meta--date date">2016-03-23</time> &#8226; <span class="post-meta__tags tags">于&nbsp;
  <a class="tag-link" href="/tags/AVFoundation/">AVFoundation</a>, <a class="tag-link" href="/tags/Cocoa/">Cocoa</a>
</span>
    </div>
    <h1 class="post-title">我是怎么踩过在 OSX 上录屏的坑的</h1>
  </header>

  <section class="post article-entry">
    <script src="/assets/js/APlayer.min.js"> </script><p>昨天开始在研究 OSX 上的屏幕录制并且实时获取视频流或图像帧的实现。遇到了非常大的阻力，各种问题，昨晚纠结了一整晚，终于在小萌的启发下慢慢找到了解决办法，把谷歌和 stackoverflow 都翻了个底朝天，最后的解决有点意外，中间还是有一些细节需要求证，然而除了 Apple Doc 已经没有任何参考文献了，而有些机制 Apple Doc 中都不会涉及。所以此刻迫不及待的想要写一篇博客，来纪念万里长征的第一步。</p>
<p>要实现录屏，有两种途径，一种是通过 <code>Core Graphic</code>， 一种是通过 <code>AVFoundation</code>。 <code>Core Graphic</code> 的话，你可以找到苹果官方的一份 <a href="https://developer.apple.com/library/mac/samplecode/SonOfGrab/Introduction/Intro.html" target="_blank" rel="external">SampleCode</a>，如果使用了 </p>
<figure class="highlight objectivec"><table><tr><td class="code"><pre><span class="line"><span class="built_in">CGImageRef</span> screenShot = <span class="built_in">CGWindowListCreateImage</span>(<span class="built_in">CGRectMake</span>(<span class="number">0.0</span>f, <span class="number">0.0</span>f, [<span class="keyword">self</span> screenRect]<span class="variable">.size</span><span class="variable">.width</span>, [<span class="keyword">self</span> screenRect]<span class="variable">.size</span><span class="variable">.height</span>), k<span class="built_in">CGWindowListOptionOnScreenOnly</span>, k<span class="built_in">CGNullWindowID</span>, k<span class="built_in">CGWindowImageDefault</span> |k<span class="built_in">CGWindowImageNominalResolution</span>);</span><br></pre></td></tr></table></figure>
<p>它的优点在于你可以根据 <code>WindowID</code> 来获取<strong>指定窗口</strong>的图像，并且可以通过 <code>ListOption</code> 来设定各种包括桌面图标，去除桌面图标，去除桌面，这些七七八八的设置，所以微信 Mac 端的截屏功能应该就是使用了上面这行代码。<strong>所以我们也可以设置一个 NSTimer， 来按照六十分之一秒一帧的速度来获取截图，并且形成一个流。</strong> 实践表明性能还不错，对于录屏这种事情烧一烧 CPU 是常有的事情，毕竟你需要按帧来计算像素，而且对于 Mac 而言，CPU 并不是什么特别大的问题 =。= 因此这种办法是<strong>可行的</strong>，然而我觉得不够优雅。</p>
<p>同样，Core Graphic 中还有一种实现办法：<code>CGDisplayCreateImage</code>：</p>
<figure class="highlight objectivec"><table><tr><td class="code"><pre><span class="line"><span class="built_in">CGImageRef</span> Ref = <span class="built_in">CGDisplayCreateImage</span>(display);</span><br><span class="line"><span class="comment">//NSData *data = (NSData *)CFBridgingRelease(CGDataProviderCopyData(CGImageGetDataProvider(Ref)));</span></span><br><span class="line">screenImg = [[<span class="built_in">NSImage</span> alloc] initWith<span class="built_in">CGImage</span>:Ref size:<span class="built_in">CGDisplayScreenSize</span>(display)];</span><br><span class="line"><span class="comment">//screenImg = [image mutableCopy];</span></span><br><span class="line"><span class="built_in">CGImageRelease</span>(Ref);</span><br><span class="line"><span class="built_in">CGDisplayRelease</span> (display);</span><br></pre></td></tr></table></figure>
<p>这种实现的机制和上述的是一致的，实现出来的效果和性能也都不错，但是同样的还是觉得不够优雅。</p>
<p>所以此刻就要转向 <code>AVFoundation</code> 了。在 <code>AVFoundation</code> 中，有一个 input 类叫做 <code>AVCaptureScreenInput</code> 这个 input 直接可以获得到当前屏幕的视频输入。这时候我想起两年前我做过视频追踪人脸的 sdk，简单地说就是通过 <code>AVDeviceCapture</code> 来获取相机的 input 然后打开一个 <code>AVSession</code>， 然后再将 input 里面的 buffer 读出来，对每一帧进行人脸检测的运算。然后我按照苹果官方的一个录屏的例子和一个 Github 上存在不多的这方面的仓库实现了简单的录屏，使用了 <code>AVCaptureMovieFileOutput</code> 作为 output。到这里的时候，一切都很顺利，输出到 mov 文件的录屏都是正常的。然后我开始了从缓冲区读取 buffer 的工作，简单来说，从缓冲区读帧是根据 <code>AVCaptureFileOutputDelegate</code> 里面的一个回调 </p>
<figure class="highlight erlang"><table><tr><td class="code"><pre><span class="line"><span class="pp">- <span class="params">(void)</span>captureOutput:<span class="params">(<span class="variable">AVCaptureFileOutput</span> *)</span>captureOutput didOutputSampleBuffer:<span class="params">(<span class="variable">CMSampleBufferRef</span>)</span>sampleBuffer fromConnection:<span class="params">(<span class="variable">AVCaptureConnection</span> *)</span>connection;</span></span><br></pre></td></tr></table></figure>
<p>来实现的。这里的 <code>CMSampleBuffers</code> 是一个 <code>Core Foundation</code> 的对象，它包含了零个或多个压缩或未压缩过的特定媒体类型的抽样，通常被用来传递媒体数据。一个 <code>CMSampleBuffers</code> 可以包含：</p>
<ul>
<li><code>CMBlockBuffer</code>, 可能包含一个或多个的 sample (话说 sample 可以翻译为帧么？还是取样的意思……)</li>
<li><code>CVImageBuffer</code> 包含了 buffer 层级的附件和 sample 层级的附件，还包括了包含的所有 sample 的格式，大小和时间信息</li>
</ul>
<p>按照 Apple Doc， 一个 <code>CMSampleBuffers</code> 就是这两种 buffer 之一的一个 wrapper， 因此每一个 <code>CMSampleBuffers</code> 只会包含其中之一。你需要用不同的方法来取出里面的数据。所以我就很正常的按照最正常的写法来取 buffer 了：</p>
<figure class="highlight dns"><table><tr><td class="code"><pre><span class="line">CVImageBufferRef imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer)<span class="comment">;</span></span><br><span class="line">CVPixelBufferLockBaseAddress(imageBuffer,0)<span class="comment">;        // Lock the image buffer</span></span><br><span class="line">        </span><br><span class="line">uint8_t *baseAddress = (uint8_t *)CVPixelBufferGetBaseAddressOfPlane(imageBuffer, 0)<span class="comment">;   // Get information of the image</span></span><br><span class="line">size_t bytesPerRow = CVPixelBufferGetBytesPerRow(imageBuffer)<span class="comment">;</span></span><br><span class="line">size_t width = CVPixelBufferGetWidth(imageBuffer)<span class="comment">;</span></span><br><span class="line">size_t height = CVPixelBufferGetHeight(imageBuffer)<span class="comment">;</span></span><br><span class="line">CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB()<span class="comment">;</span></span><br><span class="line"></span><br><span class="line">CGContextRef newContext = CGBitmapContextCreate(baseAddress, width, height, 8, bytesPerRow, colorSpace, kCGBitmapByteOrder32Little | kCGImageAlphaPremultipliedFirst)<span class="comment">;</span></span><br><span class="line">CGImageRef newImage = CGBitmapContextCreateImage(newContext)<span class="comment">;</span></span><br><span class="line">CGContextRelease(newContext)<span class="comment">;</span></span><br><span class="line"></span><br><span class="line">CGColorSpaceRelease(colorSpace)<span class="comment">;</span></span><br><span class="line">CVPixelBufferUnlockBaseAddress(imageBuffer,0)<span class="comment">;</span></span><br></pre></td></tr></table></figure>
<p>然而这个时候出了个小岔子，这里获取的 <code>CMSampleBuffers</code> 里面包的是 <code>CMBlockBuffer</code>！于是我开始查各种 stackoverflow， 无解， 一开始以为是视频格式的问题，需要按照 H264 的编码来解析，但是怎么可能呢…… 百思不得其解，即使我将 <code>CMBlockBuffer</code> 里面的 Data 读取了出来，也无法转换成 <code>NSImage</code>， 说明这个 Data 不是正常的 data。 那么有没有可能一帧被拆成多个 samples 来传输了呢…… 有可能，然而我尝试了仍然无果。</p>
<p>这时候我回头看看，发现我这里并没有将视频导出到文件的需求，有没有其他 output 来替代。偏巧我在 stackoverflow 上看到了<a href="http://stackoverflow.com/questions/15916808/capturing-blank-stills-from-a-avcapturescreeninput" target="_blank" rel="external">这个问题</a>，于是就用 <code>AVCaptureVideoDataOutput</code> 来尝试。尝试之前我已经有强烈预感了 - - 毕竟上一个 output 是直接输出到文件，而这个 output 明显是直接输出成 data。于是你只要这样给一个 output 就可以恢复正常了：</p>
<figure class="highlight objectivec"><table><tr><td class="code"><pre><span class="line"><span class="keyword">self</span><span class="variable">.output</span>  = [[<span class="built_in">AVCaptureVideoDataOutput</span> alloc] init];</span><br><span class="line">[((<span class="built_in">AVCaptureVideoDataOutput</span> *)<span class="keyword">self</span><span class="variable">.output</span>) setVideoSettings:[<span class="built_in">NSDictionary</span> dictionaryWithObjectsAndKeys:@(kCVPixelFormatType_32BGRA),kCVPixelBufferPixelFormatTypeKey, <span class="literal">nil</span>]];</span><br><span class="line"><span class="built_in">dispatch_queue_t</span> queue = dispatch_queue_create(<span class="string">"com.sergio.chan"</span>, <span class="number">0</span>);</span><br><span class="line">[(<span class="built_in">AVCaptureVideoDataOutput</span> *)<span class="keyword">self</span><span class="variable">.output</span> setSampleBufferDelegate:<span class="keyword">self</span> queue:queue];</span><br></pre></td></tr></table></figure>
<p>这时候的 sampleBuffer 已经可以正常按帧解析出来了，这里有两个问题，一个是在上面那段代码获取到一个 <code>CGImageRef</code> 的 <code>newImage</code> 对象后需要每一次都对 newImage 进行一次release，否则内存溢出就要爆炸了，一个是线程安全问题，在上面的代码里可以看出这个新的 <code>AVCaptureVideoDataOutputSampleBufferDelegate</code> 其实是在一个独立的线程上接收回调的，因此如果你要在这个 delegate 中进行 UI 操作的话，记得回到主线程操作 =。=</p>
<figure class="highlight objectivec"><table><tr><td class="code"><pre><span class="line"><span class="keyword">@try</span> &#123;</span><br><span class="line">    CVImageBufferRef imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);</span><br><span class="line">    CVPixelBufferLockBaseAddress(imageBuffer,<span class="number">0</span>);        <span class="comment">// Lock the image buffer</span></span><br><span class="line">    </span><br><span class="line">    uint8_t *baseAddress = (uint8_t *)CVPixelBufferGetBaseAddressOfPlane(imageBuffer, <span class="number">0</span>);   <span class="comment">// Get information of the image</span></span><br><span class="line">    size_t bytesPerRow = CVPixelBufferGetBytesPerRow(imageBuffer);</span><br><span class="line">    size_t width = CVPixelBufferGetWidth(imageBuffer);</span><br><span class="line">    size_t height = CVPixelBufferGetHeight(imageBuffer);</span><br><span class="line">    <span class="built_in">CGColorSpaceRef</span> colorSpace = <span class="built_in">CGColorSpaceCreateDeviceRGB</span>();</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">CGContextRef</span> newContext = <span class="built_in">CGBitmapContextCreate</span>(baseAddress, width, height, <span class="number">8</span>, bytesPerRow, colorSpace, k<span class="built_in">CGBitmapByteOrder32Little</span> | k<span class="built_in">CGImageAlphaPremultipliedFirst</span>);</span><br><span class="line">    <span class="built_in">CGImageRef</span> newImage = <span class="built_in">CGBitmapContextCreateImage</span>(newContext);</span><br><span class="line">    <span class="built_in">CGContextRelease</span>(newContext);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">CGColorSpaceRelease</span>(colorSpace);</span><br><span class="line">    CVPixelBufferUnlockBaseAddress(imageBuffer,<span class="number">0</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">NSImage</span> *image = [[<span class="built_in">NSImage</span> alloc] initWith<span class="built_in">CGImage</span>:newImage size:[<span class="keyword">self</span> screenRect]<span class="variable">.size</span>];</span><br><span class="line">    <span class="built_in">CGImageRelease</span>(newImage);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">dispatch_async</span>(dispatch_get_main_queue(), ^&#123;</span><br><span class="line">        <span class="keyword">if</span>(<span class="keyword">self</span><span class="variable">.imageView</span>) &#123;</span><br><span class="line">            <span class="keyword">self</span><span class="variable">.imageView</span><span class="variable">.image</span> = image;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">@catch</span> (<span class="built_in">NSException</span> *exception) &#123;</span><br><span class="line">    <span class="built_in">NSLog</span>(<span class="string">@"Error at %@"</span>,exception<span class="variable">.debugDescription</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">@finally</span> &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>PS. Cocoa 中获取 ScreenRect 的方法如下：</p>
<figure class="highlight objectivec"><table><tr><td class="code"><pre><span class="line">- (<span class="built_in">NSRect</span>)screenRect</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">NSRect</span> screenRect;</span><br><span class="line">    <span class="built_in">NSArray</span> *screenArray = [<span class="built_in">NSScreen</span> screens];</span><br><span class="line">    <span class="built_in">NSScreen</span> *screen = [screenArray objectAtIndex: <span class="number">0</span>];</span><br><span class="line">    screenRect = [screen frame];<span class="comment">//[screen visibleFrame];</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> screenRect;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里后来又遇到一个小坑。如果使用的是 visibleFrame， 那么如果你的窗口处于全屏模式，获取 visibleFrame 的时候其实会把上面状态栏的那部分区域给省略了，因为计算 visibleFrame 的时候估计不考虑状态栏是否隐藏吧，所以这里用 frame 更好。</p>
</blockquote>
<p>这里从 delegate 中获取到每一帧的数据之后就可以对每一帧进行压缩，并且以 Data 的形式进行传输了。差点忘记最后介绍一下 <code>AVCaptureScreenInput</code> 的一些特性了：</p>
<figure class="highlight objectivec"><table><tr><td class="code"><pre><span class="line"><span class="keyword">self</span><span class="variable">.input</span><span class="variable">.capturesMouseClicks</span> = <span class="literal">YES</span>;</span><br><span class="line"><span class="keyword">self</span><span class="variable">.input</span><span class="variable">.minFrameDuration</span> = CMTimeMake(<span class="number">1</span>, <span class="number">60</span>);</span><br><span class="line"><span class="keyword">self</span><span class="variable">.input</span><span class="variable">.scaleFactor</span> = <span class="number">0.5</span>f;</span><br><span class="line"><span class="keyword">self</span><span class="variable">.input</span><span class="variable">.cropRect</span> = [<span class="keyword">self</span> screenRect];</span><br></pre></td></tr></table></figure>
<p>首先 <code>AVCaptureScreenInput</code> 可以记录下鼠标移动的轨迹，还可以记录鼠标的点击事件（自行体验），第二个属性设置的是最大帧率，也就是60帧一秒。第三个和第四个属性顾名思义分别是缩放的比例和最后输出的裁剪区域，设置这两个属性可以减少每一帧的大小，也就是说在输入的时候就已经限制过大小了，然后你再可以进行一些压缩什么的。最后其实 <code>AVCaptureScreenInput</code> 还有一个关键的属性，但是现在已经被废弃了，因为苹果已经把这个属性内置成系统默认了😂 <strong>重复帧会被自动取消</strong>，这在以前的版本是可以通过一个属性设置的，现在已经被默认采用了。</p>
<p>多余的说几点：</p>
<ul>
<li>其实 Core Media 那层有很多知识点，但是苦于文档太少，研究的人也太少，因此实在是举步维艰，感兴趣的朋友可以参考一下<a href="https://developer.apple.com/library/mac/documentation/CoreMedia/Reference/CMSampleBuffer/" target="_blank" rel="external">苹果的 Reference </a>看下这块的内容。</li>
<li>其实可能有些人知道在 <code>AVFoundation</code> 下面，<code>Core Media</code>之上还有一层叫做 <code>Video ToolBox</code>，这在2012年那会儿都是只有越狱的设备才能调用到的 Private API，但是2014年的 WWDC 苹果将这一层开放出来了，因此你可以在 <code>AVFoundation</code> 更深入的层次去做视频编码解码和流处理，这块的知识我这次只看了个大概，留下了一些资料出处：<a href="https://github.com/McZonk/VideoToolboxPlus" target="_blank" rel="external">Github</a>  <a href="https://developer.apple.com/videos/play/wwdc2014/513/" target="_blank" rel="external">WWDC</a></li>
</ul>
<p>最后，最重要的是！代码已经整理成开源库放在 <a href="https://github.com/RavenTech-GrowthHacker/RTScreenRecorder" target="_blank" rel="external">Github</a> 上了！</p>

  </section>

</article>


<section class="post-comments">
  <!-- 多说评论框 start -->
  <div class="ds-thread" data-thread-key="http://sergiochan.github.io/2016/03/23/我是怎么踩过在-OSX-上录屏的坑的/" data-title="我是怎么踩过在 OSX 上录屏的坑的" data-url="http://sergiochan.github.io/2016/03/23/我是怎么踩过在-OSX-上录屏的坑的/"></div>
  <!-- 多说评论框 end -->
  <!-- 多说公共JS代码 start (一个网页只需插入一次) -->
  <script type="text/javascript">
  var duoshuoQuery = {short_name:"sergiochan"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  </script>
<!-- 多说公共JS代码 end -->
</section>



            <footer class="footer">
    <span class="footer__copyright">
        本站点采用<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>
    </span>
    <span class="footer__copyright">
        &copy; 2014 - 2016 本站由 <a href="/">@Sergio Chan</a> 创建,
    </span>
</footer>

        </div>
    </div>

    <script src="http://cdn.bootcss.com/jquery/2.1.4/jquery.min.js" type="text/javascript"></script>
    <script src="/js/main.js" type="text/javascript"></script>

     
</body>
</html>
